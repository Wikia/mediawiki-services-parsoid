/**
 * Combined Wiki (MediaWiki) and HTML tokenizer based on pegjs. Emits several
 * chunks of tokens (one chunk per top-level block matched) and eventually an
 * end event. Tokens map to HTML tags as far as possible, with custom tokens
 * used where further processing on the token stream is needed.
 */
{

    var pegIncludes = options.pegIncludes,
        Util = pegIncludes.Util,
        PegTokenizer = pegIncludes.PegTokenizer,
        defines = pegIncludes.defines,
        constants = pegIncludes.constants,
        tu = pegIncludes.tu;

    // define some constructor shortcuts
    var KV = defines.KV,
        TagTk = defines.TagTk,
        SelfclosingTagTk = defines.SelfclosingTagTk,
        EndTagTk = defines.EndTagTk,
        NlTk = defines.NlTk,
        CommentTk = defines.CommentTk,
        EOFTk = defines.EOFTk;

    var inline_breaks = tu.inline_breaks;
    var stops = new tu.SyntaxStops();

    // Current extension/include tag being parsed.
    var currExtTag = null;

    // text start position
    var textStart = 0;

    /*
     * Emit a chunk of tokens to our consumers.  Once this has been done, the
     * current expression can return an empty list (true).
     */
    var emitChunk = function (tokens) {
        // shift tsr of all tokens by offset
        Util.shiftTokenTSR(tokens, options.srcOffset);
        options.env.log("trace/peg", options.pegTokenizer.pipelineId, "---->  ", tokens);
        // limit the size of individual chunks
        var chunkLimit = 100000;
        if (tokens.length > chunkLimit) {
            var i = 0,
                l = tokens.length;

            while (i < l) {
                //console.warn('emitting partial chunk', i);
                options.cb(tokens.slice(i, i+chunkLimit));
                i += chunkLimit;
            }
        } else {
            //console.warn('emitting single chunk', tokens.length);
            options.cb(tokens);
        }
    };

}

/*********************************************************
 * The top-level production
 *********************************************************/

start
  = tlb* newline* {
      // end is passed inline as a token, as well as a separate event for now.
      emitChunk( [ new EOFTk( ) ] );
      return true;
  }

/*
 * Redirects can only occur as the first thing in a document.  See
 * WikitextContent::getRedirectTarget()
 */
redirect
  = rw:redirect_word
    sp:space_or_newline*
    c:( ":" space_or_newline* )?
    link:(wl:wikilink { return wl[0]; })
{
    if (!link || link.constructor === String) {
        peg$currPos = peg$reportedPos;
        return peg$FAILED;
    }
    // Set the wikilink's tsr to be zero length. That token is synthetic and
    // the full tsr range is used by the redirect token. Anything with a zero
    // width will never be serialized using selser, which is what we want here
    // as there is no source for it.
    link.dataAttribs.tsr[0] = link.dataAttribs.tsr[1];

    if (sp) { rw += sp.join(''); }
    if (c) { rw += c[0] + c[1].join(''); }
    // Build a redirect token
    var redirect = new SelfclosingTagTk('mw:redirect',
            [Util.lookupKV(link.attribs,'href')],
            {
                src: rw,
                tsr: [peg$reportedPos, peg$currPos],
                linkTk: link
            });
    return redirect;
}

/* The 'redirect' magic word.
 * The leading whitespace allowed is due to the PHP trim() function.
 */
redirect_word = sp:[ \t\n\r\0\x0b]* rw:((!space_or_newline ![:\[] c:.{return c;})+)
{
    if ( !rw ) {
        rw = "";
    }
    rw = rw.join('');
    if ( options.env.conf.wiki.getMagicWordMatcher( 'redirect' ).test( rw ) ) {
        return sp.join('') + rw;
    }
    peg$currPos = peg$reportedPos;
    return peg$FAILED;
}

/*
 * This production exists to support tokenizing the document in chunks.
 * It stops tokenization after each block and yields to the node.js
 * event-loop to schedule other pending event handlers.
 *
 * It needs to keep track of sol-state so when tokenization resumes,
 * it knows whether it is in sol-state or not.
 */
toplevelblock =
  tlb save_sol_state {
        var parsedInput = input.substring(0, peg$currPos),
            newInput = input.substring(peg$currPos),
            newOffset = (options.srcOffset || 0) + peg$currPos;

        // Trick the tokenizer into ending parsing
        input = parsedInput;

        // console.warn("Yield @pos: " + newOffset + "; input len: " + newInput.length);

        return { eof: false, newInput: newInput, newOffset: newOffset };
  }
  / newline* eof {
        // Clear saved sol state!
        options.pegTokenizer.savedSOL = null;
        // console.warn("-- EOF!");
        emitChunk( [ new EOFTk( ) ] );

        return { eof: true };
  }

save_sol_state =
    & sol { options.pegTokenizer.savedSOL = true; return true; }
  / &     { options.pegTokenizer.savedSOL = false; return true; }

/*
 * A document (start production) is a sequence of toplevelblocks. Tokens are
 * emitted in chunks per toplevelblock to avoid buffering the full document.
 */
tlb
  = !eof b:block {
    // Clear the tokenizer's backtracking cache after matching each
    // toplevelblock. There won't be any backtracking as a document is just a
    // sequence of toplevelblocks, so the cache for previous toplevelblocks
    // will never be needed. This frees up a lot of memory: In the case of
    // [[:en:Barack Obama]], the difference is about 360M vs. 110M.
    peg$cache = {};

    // Add source offsets for round-tripping. XXX: Add these not just for
    // toplevelblocks!
    var tokens;
    if ( Array.isArray(b) && b.length ) {
        tokens = tu.flattenIfArray(b);
    } else if (b && b.constructor === String) {
        tokens = [b];
    }

    // Emit tokens for this toplevelblock. This feeds a chunk to the parser pipeline.
    if ( tokens ) {
        emitChunk( tokens );
    }

    // We don't return any tokens to the start production to save memory. We
    // just emitted them already to our consumers.
    return true;
  }

/*
 * The actual contents of each block.
 */
block
  = &sof r:redirect {return [r];} // has to be first alternative; otherwise gets parsed as a <ol>
    / block_lines
    / & '<' rs:( pre // tag variant can start anywhere
            / c:comment &eolf { return c; }
            / nowiki
            // avoid a paragraph if we know that the line starts with a block tag
            / bt:block_tag { return [bt]; }
            ) { return rs; }
    / paragraph
    // Inlineline includes generic tags; wrapped into paragraphs in token
    // transform and DOM postprocessor
    / inlineline
    / s:sol !inline_breaks { return s; }

/*
 * A block nested in other constructs. Avoid eating end delimiters for other
 * constructs by checking against inline_breaks first.
 */
nested_block = !inline_breaks b:block { return b; }

nested_block_line = bs:(!sol !inline_breaks b:block { return b; })* {
    return tu.flattenIfArray(bs);
}

/*
 * The same, but suitable for use inside a table construct.
 * Doesn't match table_heading_tag, table_row_tag, table_data_tag,
 * table_caption tag, or table_end_tag, although it does allow
 * table_start_tag (for nested tables).
 */
nested_block_in_table
  =
    // avoid recursion via nested_block_in_table, as that can lead to stack
    // overflow in large tables
    // See https://bugzilla.wikimedia.org/show_bug.cgi?id=57670
    & { return stops.push('tableDataBlock', true ); }
    // XXX: don't rely on a lame look-ahead like this; use syntax stops
    // instead, so that multi-line th content followed by a line prefixed with
    // a comment is also handled. Alternatively, implement a sol look-behind
    // assertion accepting spaces and comments.
    !(sol (space* sol)? space* (pipe / "!")) b:nested_block {
        stops.pop('tableDataBlock');
        return b;
    }
  / & { return stops.pop('tableDataBlock'); }

/*
 * Line-based block constructs.
 */
block_lines
  = s:sol
    // eat an empty line before the block
    s2:(os:optionalSpaceToken so:sol { return os.concat(so); })?
    bl:block_line {
        //console.warn( 'bl', JSON.stringify(bl, null, 2) );
        var s2_ = (s2 !== null) ? s2 : [];
        return s.concat(s2_, bl);
    }

/*
 * Block structures with start-of-line wiki syntax
 */
block_line
  = h
  / lists
  / st:optionalSpaceToken
    r:( & [{}|!] tl:table_lines { return tl; }
      // tag-only lines should not trigger pre either
      / bts:(bt:block_tag stl:optionalSpaceToken { return bt.concat(stl); })+
        &eolf { return bts; }
      ) {
          return st.concat(r);
      }
  / ! { return stops.counters.nopre; } pi:pre_indent { return pi; }
  / pre
  / // Horizontal rules
    "----" d:"-"*
    // Check if a newline or content follows
    lineContent:( &sol { return undefined; } / { return true; } ) {
      if (d.length > 0) {
          return new SelfclosingTagTk( "hr", [],
                    {
                        tsr: [peg$reportedPos, peg$currPos],
                        extra_dashes: d.length,
                        lineContent: lineContent
                    } );
      } else {
          return new SelfclosingTagTk( "hr", [],
                    {
                        tsr: [peg$reportedPos, peg$currPos],
                        lineContent: lineContent
                    } );
      }
  }

/*
 * A paragraph. We don't emit 'p' tokens to avoid issues with template
 * transclusions, <p> tags in the source and the like. Instead, we perform
 * some paragraph wrapping on the token stream and the DOM.
 */
paragraph
  = s1:sol s2:sol c:inlineline {
      return s1.concat(s2, /* [new TagTk('p')],*/ c);
  }

br = s:optionalSpaceToken &newline {
    return s.concat(
            [
                new SelfclosingTagTk( 'br', [], {tsr: [peg$reportedPos, peg$currPos]} )
            ]
        );
}

/*
 * Syntax stops: Avoid eating significant tokens for higher-level productions
 * in nested inline productions.
 *
 * Repeated testing of flags is not terribly efficient. See new and faster
 * version below.
 */

/*
 * Syntax stops: Avoid eating significant tokens for higher-level productions
 * in nested inline productions.
 */
inline_breaks
  = & {
        //console.warn('ilbf: ' + input.substr(peg$currPos, 5) );
        //if ( null !== options.parser.inline_breaks( input, peg$currPos, stops ) ) {
        //    console.warn('ilb break: ' + pp(input.substr(peg$currPos, 5)) );
        //} else {
        //    console.warn('ilb no break: ' + pp(input.substr(peg$currPos, 5)) );
        //}
        return inline_breaks( input, peg$currPos, stops );
      }

pre_start = "<" pre_tag_name (' '+ [^>]*)? ">"

inline
  = c:(urltext / (!inline_breaks !pre_start r:(inline_element / . ) { return r; }))+ {
      //console.warn('inline out:' + pp(c));
      return tu.flatten_stringlist( c );
  }

inlineline
  = c:(urltext
          / !{ return inline_breaks( input, peg$currPos, stops ); } // inline_breaks
            !pre_start
            r:(inline_element / [^\r\n]) { return r; })+ {
      //console.warn('inlineline out:' + pp(c) + input.substr(peg$reportedPos, peg$currPos));
      return tu.flatten_stringlist( c );
  }

inline_element
  = //& { dp('inline_element enter' + input.substr(peg$currPos, 10)); return true; }
    & '<' r:( nowiki
          / xmlish_tag
          / comment
          ) { return r; }
    /// & '{' ( & '{{{{{' template / tplarg / template )
    / & '{' r:tplarg_or_template_or_broken { return r; }
    / & '}' r:broken_template { return r; }
    /// & '{' ( tplarg / template )
     // Eat three opening brackets as text, but handle '[[[[' differently
     // so, that '[[[[Foo]]]]' parses as '[[<a..>Foo</a>]]'
    / (!'[' / sol) '[[[' !'[' { return '[[['; }
    / & '[' r:( wikilink / extlink ) { return r; }
    / & "'" r:quote { return r; }

/* Headings  */

h = & "=" // guard, to make sure '='+ will match.
          // XXX: Also check to end to avoid inline parsing?
    r:(
     s:'='+ // moved in here to make s accessible to inner action
     & { return stops.inc('h'); }
     c:nested_block_line
     e:'='+
     endTPos:({ return peg$currPos; })
     spc:(spaces / comment)*
     &eolf
     {
        stops.dec('h');
        var level = Math.min( s.length, e.length );
        level = Math.min( 6, level );
        // convert surplus equals into text
        if (s.length > level) {
            s = s.join('');
            var extras1 = s.substr(0, s.length - level);
            if (c[0].constructor === String) {
                c[0] = extras1 + c[0];
            } else {
                c.unshift( extras1 );
            }
        }
        if(e.length > level) {
            e = e.join('');
            var extras2 = e.substr(0, e.length - level),
                lastElem = c[c.length - 1];
            if(lastElem.constructor === String) {
                c[c.length-1] += extras2;
            } else {
                c.push( extras2 );
            }
        }

        return [new TagTk( 'h' + level, [], { tsr: [peg$reportedPos, peg$reportedPos+level] } )]
                .concat(c, [
                        new EndTagTk( 'h' + level, [],
                            { tsr: [endTPos - level, endTPos]} ),
                        spc
                        ]);
      }
    / & { stops.dec('h'); return false; }
    ) { return r; }

comment
    ='<!--' c:comment_chars* ('-->' / eof)
    {
        return [new CommentTk( c.join(''), { tsr: [peg$reportedPos, peg$currPos] } )];
    }

comment_chars
  = c:[^-] { return c; }
  / c:'-' !'->' { return c; }



// Behavior switches. See https://www.mediawiki.org/wiki/Help:Magic_words#Behavior_switches
behavior_switch
  = '__' behavior:behavior_text '__'
{
    return [
        new SelfclosingTagTk(
            'behavior-switch',
            [new KV('word', '__' + behavior + '__')],
            {
                tsr: [peg$reportedPos, peg$currPos],
                src: input.substring( peg$reportedPos, peg$currPos )
            }
        )
    ];
}

behavior_text = text:( &( !'__' ) tc:text_char { return tc; } )* {
    return tu.flatten_stringlist( text );
}

/**************************************************************
 * External (bracketed and autolinked) links
 **************************************************************/

autolink
  = ! { return stops.onStack('extlink'); }
  r:(
      // urllink, inlined
      target:autourl {
        // Special case handling for trailing parentheses: remove from link if
        // there is no opening parenthesis in the link
        if ( Array.isArray(target) ) {
            var end = target[target.length - 1];
            if ( !/[(]/.test( target[0] ) &&
                 end.constructor === String &&
                 /[)]$/.test( end )
            ) {
                target.pop();
                peg$currPos--;
            }
        } else {
            if (!/[(]/.test(target) && /[)]$/.test(target)) {
                target = target.substr(0, target.length - 1);
                peg$currPos--;
            }
        }
        var res = [ new SelfclosingTagTk( 'urllink', [new KV('href', target)], { tsr: [peg$reportedPos, peg$currPos] } ) ];
          return res;
      }
    / autoref
    / isbn) { return r; }

extlink
  = ! { return stops.onStack('extlink'); } // extlink cannot be nested
  r:(
        "["
        & { return stops.push('extlink', true); }
        target:extlink_preprocessor_text
        & { return Util.isProtocolValid( target, options.env ); }
        sp:( space / [\u00A0\u1680\u180E\u2000-\u200A\u202F\u205F\u3000] )*
        targetOff:({ return peg$currPos; })
        content:(
                t1:(
                    & { return  stops.push('pipe', false); }
                    t:inlineline { stops.pop('pipe'); return t; }
                    / ! { return stops.pop('pipe'); }
                ) { return t1; }
              )?
        "]" {
            stops.pop('extlink');
            //if ( text === '' ) {
            //    // XXX: Link numbering should be implemented in post-processor.
            //    text = [ "[" + linkCount + "]" ];
            //    linkCount++;
            //}
            //console.warn( 'extlink text: ' + pp( text ) );
            return [
                new SelfclosingTagTk( 'extlink', [
                    new KV('href', target),
                    new KV('mw:content', content),
                    new KV('spaces', sp.join(''))
                ], {
                    targetOff: targetOff,
                    tsr: [peg$reportedPos, peg$currPos],
                    contentOffsets: [targetOff, peg$currPos-1]
                })
            ];
        }
      / br:"[" & { return stops.pop('extlink'); } { return br; }
    ) { return r; }

autoref
  = ref:('RFC' / 'PMID') space_or_newline+ identifier:[0-9]+
{
    identifier = identifier.join('');

    var base_urls = {
            'RFC'  : '//tools.ietf.org/html/rfc%s',
            'PMID' : '//www.ncbi.nlm.nih.gov/pubmed/%s?dopt=Abstract'
        },
        url = tu.sprintf(base_urls[ref], identifier);

    return [
        new SelfclosingTagTk( 'extlink', [
           new KV('href', tu.sprintf(base_urls[ref], identifier)),
           new KV('mw:content', [ref, identifier].join(' ')),
           new KV( 'typeof', 'mw:ExtLink/' + ref )
        ],
        {stx: "magiclink", tsr: [peg$reportedPos, peg$currPos]})
    ];
}

isbn
  = 'ISBN' space_or_newline+
    head:[0-9]
    digits:(d:( c:[- ] &[0-9] { return c; } / [0-9] ) { return d; } )+
    tail:('-X')?
    end_of_word
{
    // TODO: round-trip non-decimals too!
    var isbn = [head, digits.join(''), tail].join(''),
        isbncode = isbn.replace(/[^\dX]/g, '');

    // ISBNs can only be 10 or 13 chars long
    if ([10, 13].indexOf(isbncode.length) === -1) {
        // just return the string
        return [ input.substring( peg$reportedPos, peg$currPos ) ];
    }

    return [
        new SelfclosingTagTk( 'extlink', [
           new KV('href', 'Special:BookSources/' + isbncode),
           new KV('mw:content', 'ISBN ' + isbn),
           new KV('typeof', 'mw:ExtLink/ISBN')
        ],
        {stx: "magiclink", tsr: [peg$reportedPos, peg$currPos]})
    ];
}


/* Default URL protocols in MediaWiki (see DefaultSettings). Normally
 * these can be configured dynamically. */

url_protocol =
    & { return Util.isProtocolValid( input.substr( peg$currPos ), options.env ); }
    h:[a-zA-Z\/]+ c:':'? s:'//'?
{
	h = h.join( '' );
	if ( c ) {
		h += c;
	}
	if ( s ) {
		h += s;
	}
    return h;
}

// javascript does not support unicode features..
unicode_separator_space = [ \u00A0\u1680\u180E\u2000-\u200A\u202F\u205F\u3000]


urlencoded_char = "%" c0:[0-9a-fA-F] c1:[0-9a-fA-F] {
    try {
        return decodeURI("%" + c0 + c1);
    } catch ( e ) {
        // Reject the match, and allow other fall-back productions to have a
        // go at it.
        peg$currPos = peg$reportedPos;
        return peg$FAILED;
    }
}

//[^][<>"\\x00-\\x20\\x7F\p{Zs}]

// no punctuation, and '{<' to trigger directives
no_punctuation_char = [^ :\]\[\r\n"'<>\x00-\x20\x7f,.&%\u00A0\u1680\u180E\u2000-\u200A\u202F\u205F\u3000{]

// this is the general url production
// on the PHP side, the path part matches EXT_LINK_URL_CLASS
// which is '[^][<>"\\x00-\\x20\\x7F\p{Zs}]'
// the 's' and 'r' pieces below match the characters in
// EXT_LINK_URL_CLASS which aren't included in no_punctuation_char
url
  = proto:url_protocol
    addr:( ipv6_address / ipv4_address )?
    path:(  ( !{ return inline_breaks( input, peg$currPos, stops ); } // inline_breaks
              c:no_punctuation_char
              { return c; }
            )
            / s:[.:,']  { return s; }
            / comment
            / tplarg_or_template
            / ! ( "&" ( [lL][tT] / [gG][tT] ) ";" )
                r:(
                    & "&" he:htmlentity { return he; }
                  / [&%{]
                ) { return r; }
         )+
{
    proto += addr || '';
    return tu.flatten_string( [proto].concat( path ) );
}

// this is the somewhat-restricted production used in autolinks
autourl
  = proto:url_protocol
    addr:( ipv6_address / ipv4_address )?
    path:(  ( !{ return inline_breaks( input, peg$currPos, stops ); } // inline_breaks
              c:no_punctuation_char
              { return c; }
            )
            / s:[.:,] !(space / eolf) { return s; }
            / comment
            / tplarg_or_template
            / ! ( "&" ( [lL][tT] / [gG][tT] ) ";" )
                r:(
                    htmlentity
                  / [&%{]
                ) { return r; }
         )+
{
    proto += addr || '';
    return tu.flatten_string( [proto].concat( path ) );
}

ipv4_address
  = a:([0-9]* '.' [0-9]* '.' [0-9]* '.' [0-9]*)
{
    // a will always be an array
    return tu.flattenIfArray( a ).join('');
}

ipv6_address
  = a:('[' [0-9]* ':' [0-9]* ':' [0-9]* ':' [0-9]* ':' [0-9]* ':' [0-9]* ':' [0-9]* ']')
{
    // a will always be an array
    return tu.flattenIfArray( a ).join('');
}


/**************************************************************
 * Templates, -arguments and wikilinks
 **************************************************************/

/*
 * Precedence: template arguments win over templates. See
 * http://www.mediawiki.org/wiki/Preprocessor_ABNF#Ideal_precedence
 * 4: {{{{·}}}} → {·{{{·}}}·}
 * 5: {{{{{·}}}}} → {{·{{{·}}}·}}
 * 6: {{{{{{·}}}}}} → {{{·{{{·}}}·}}}
 * 7: {{{{{{{·}}}}}}} → {·{{{·{{{·}}}·}}}·}
 */
tplarg_or_template
    = & '{{{{{{{' ob:'{' tpl:tplarg_or_template eb:'}' { return [ob, tpl, eb]; }
    / & ( '{{{' &'{{{' tplarg ) r:tplarg { return r; }
    // tplarg in template
    / & ( '{{' &'{{{' tplarg )  r:template { return r; }
    / tplarg
    / template

tplarg_or_template_or_broken
    = tplarg_or_template / broken_template

tplarg_or_template_or_bust
	= (tplarg_or_template / .)+

broken_template
  = v:( '{{{' / '}}}' / '{{' / '}}' )+
{
    return [
        new TagTk('span', [ new KV('typeof', 'mw:Nowiki') ], { tsr: [peg$reportedPos, peg$reportedPos], src: input.substring(peg$reportedPos, peg$currPos) } )]
            .concat(v, [new EndTagTk( 'span', [ new KV('typeof', 'mw:Nowiki') ], { tsr: [peg$currPos, peg$currPos] }) ]);
}


template
  = "{{" nl_comment_space*
    target:template_param_value
    params:(nl_comment_space* "|"
                r:( p0:({return peg$currPos;}) v:nl_comment_space* p:({return peg$currPos;}) &"|"
                    { return new KV( '', tu.flattenIfArray(v), [p0,p0,p0,p]); } // empty argument
                    / template_param
                  ) { return r; }
            )*
    nl_comment_space*
    "}}" {
      // Insert target as first positional attribute, so that it can be
      // generically expanded. The TemplateHandler then needs to shift it out
      // again.
      params.unshift( new KV(tu.flattenIfArray( target.tokens ), '', target.srcOffsets) );
      var obj = new SelfclosingTagTk( 'template', params, {tsr: [peg$reportedPos, peg$currPos], src: input.substring(peg$reportedPos, peg$currPos)} );
      //console.warn( 'tokenizer template ' + peg$currPos + );
      //console.warn('template @' + peg$currPos + '::' + input.substr(peg$currPos, 40) );
      return obj;
    }

// XXX: support template and args in target!
//template_target
//  = h:( !"}}" x:([^|\n]) { return x } )* { return h.join('') }

tplarg
  = "{{{"
    name:template_param_value?
    params:( nl_comment_space*
              '|' nl_comment_space*
               r:(
                    &'}}}' { return new KV( '', ''); }
                    / template_param
               ) { return r; }
           )*
    nl_comment_space*
    "}}}" {
      if (name) {
        params.unshift( new KV( tu.flattenIfArray(name.tokens), '', name.srcOffsets ) );
      } else {
        params.unshift( new KV( '', '') );
      }
      var obj = new SelfclosingTagTk( 'templatearg', params, {tsr: [peg$reportedPos, peg$currPos], src: input.substring(peg$reportedPos, peg$currPos)} );
      //console.warn( 'tokenizer tplarg ' + JSON.stringify( obj, null, 2 ));
      //console.warn('template arg @' + peg$currPos + '::' + input.substr(peg$currPos, 40) );
      return obj;
  }

template_param
  = name:template_param_name
    // MW accepts |foo | = bar | as a single param..
    (p:'|' sp:space_or_newline* &'=' { return [p, sp]; })?
    val:(
        kEndPos:({return peg$currPos;})
        optionalSpaceToken
        "="
        vStartPos:({return peg$currPos;})
        optionalSpaceToken
        tpv:template_param_value? {
            return { kEndPos:kEndPos, vStartPos: vStartPos, value: (tpv && tpv.tokens) || [] };
        }
    )? {
      //console.warn( 'named template_param matched' + pp([name, value ]) );
      if ( val !== null ) {
          if ( val.value !== null ) {
            return new KV( name, tu.flattenIfArray( val.value ), [peg$reportedPos, val.kEndPos, val.vStartPos, peg$currPos] );
          } else {
            return new KV(tu.flattenIfArray( name ), '', [peg$reportedPos, val.kEndPos, val.vStartPos, peg$currPos] );
          }
      } else {
        return new KV('', tu.flattenIfArray(name), [peg$reportedPos, peg$reportedPos, peg$reportedPos, peg$currPos] );
      }
    }
  // empty parameter
  / & [|}] { return new KV('', '', [peg$reportedPos, peg$reportedPos, peg$reportedPos, peg$currPos] ); }


// FIXME: handle template args and templates in key! (or even parser functions?)
template_param_name
  = & { return stops.push( 'equal', true ); }
    tpt:(template_param_text / &'=' { return ''; })
    {
        stops.pop( 'equal' );
        //console.warn( 'template param name matched: ' + pp( tpt ) );
        return tpt;
    }

  / & { return stops.pop( 'equal' ); }
  //= h:( !"}}" x:([^=|\n]) { return x } )* { return h.join(''); }

template_param_value
  = & { stops.inc( 'nopre' ); return stops.push( 'equal', false ); }
    tpt:template_param_text
    {
        stops.dec( 'nopre' );
        stops.pop( 'equal' );
        //console.warn( 'template param value matched: ' + pp( tpt ) );
        return { tokens: tpt, srcOffsets: [peg$reportedPos, peg$currPos] };
    }
  / & { stops.dec( 'nopre' ); return stops.pop( 'equal' ); }

template_param_text
  = & { /*console.warn( 'tpt: ' +
          input.substr( peg$currPos - 10, 9) +
          input[peg$currPos].green +
          input.substr( peg$currPos +1, 9) ); */
        // re-enable tables within template parameters
        stops.push('table', false );
        stops.push('extlink', false);
        stops.push('pipe', true);
        return stops.inc('template');
    }
    il:(nested_block / newlineToken)+ {
        stops.pop('table');
        stops.pop('extlink');
        stops.pop('pipe');
        stops.dec('template');
        //console.warn( 'tpt match: ' + pp (il) + " stops: " + pp(stops));
        // il is guaranteed to be an array -- so, tu.flattenIfArray will
        // always return an array
        var r = tu.flattenIfArray( il );
        //console.warn('tpl param name' + peg$currPos + r[0] + '::' + input.substr(peg$currPos, 40) );
        if ( r.length === 1 && r[0].constructor === String ) {
            r = r[0];
        }

        return r;
    }
  / & { stops.pop('table'); stops.pop('extlink'); stops.pop('pipe'); return stops.dec('template'); }


wikilink_content
  = lcs:( pipe startPos:({ return peg$currPos; }) lt:link_text? {
        var maybeContent = new KV( 'mw:maybeContent', lt, [startPos, peg$currPos] );
        maybeContent.vsrc = input.substring( startPos, peg$currPos );
        return maybeContent;
    } ) + {
        if ( lcs.length === 1 && lcs[0].v === null ) {
            return { content: [], pipetrick: true };
        } else {
            return { content: lcs };
        }
    }

// TODO: handle link prefixes as in al[[Razi]]
wikilink
  = "[["
    ! url
    //target:link_target
    // XXX: disallow pipe!
    target:wikilink_preprocessor_text?
    tpos:({return peg$currPos;})
    lcontent:wikilink_content?
    "]]"
  {
      if ( lcontent === null ) {
          lcontent = { content: [] };
      }
      //console.warn('lcontent: ' + JSON.stringify( lcontent, null, 2 ) );

      if ( target === null ){
        var src = input.substring(peg$reportedPos, peg$currPos);
        return [src];
      }


      var obj = new SelfclosingTagTk( 'wikilink' ),
          textTokens = [],
          hrefKV = new KV('href', target);
      hrefKV.vsrc = input.substring(peg$reportedPos+2, tpos);
      // XXX: Point to object with path, revision and input information
      //obj.source = input;
      obj.attribs.push(hrefKV);
      obj.attribs = obj.attribs.concat( lcontent.content );
      obj.dataAttribs = {
          tsr: [peg$reportedPos, peg$currPos],
          src: input.substring( peg$reportedPos, peg$currPos ),
          pipetrick: lcontent.pipetrick
      };
      return [obj];
  }

// This production is identical to the 'inline' fragment except
// that tables are allowed inside image captions.
link_text_fragment
  = c:((sol table_lines) / urltext
          / (!inline_breaks
              !pre_start
              r:( inline_element / '[' text_char+ ']' / . ) {
                  return r;
              })
    )+ {
      //console.warn('inline out:' + pp(c));
      return tu.flatten_stringlist( c );
  }

link_text
  = & { return stops.inc('linkdesc'); }
    h:link_text_fragment
    // 'equal' syntaxFlag is set for links in template parameters. Consume the
    // '=' here.
    hs:( '=' link_text_fragment )?
    {
        //console.warn('link_text' + pp(h) + pp(hs));
        stops.dec('linkdesc');
        if( hs !== null ) {
            return h.concat(hs);
        } else {
            return h;
        }
    }
  / & { return stops.dec('linkdesc'); }

link_option
  = & { stops.push('pipe', true); return stops.inc('linkdesc'); }
    h:inline
    // 'equal' syntaxFlag is set for links in template parameters. Consume the
    // '=' here.
    hs:( '=' inline)?
    {
        //console.warn('link_option' + pp(h) + pp(hs));
        stops.pop('pipe');
        stops.dec('linkdesc');
        if( hs !== null ) {
            return h.concat(hs);
        } else {
            return h;
        }
    }
  / & { stops.pop('pipe'); return stops.dec('linkdesc'); }

link_end = "]]"

/* Generic quote production for italic and bold, further processed in a token
 * stream transformation in doQuotes. Relies on NlTk tokens being emitted
 * for each line of text to balance quotes per line.
 *
 * We are not using a simple pair rule here as we need to support mis-nested
 * bolds/italics and MediaWiki's special heuristics for apostrophes, which are
 * all not context free. */
quote = "''" x:"'"* {
    // sequences of four or more than five quotes are assumed to start
    // with some number of plain-text apostrophes.
    var quotes = "''" + x.join(''), plainticks = 0, result = [];
    if (quotes.length === 4) {
        plainticks = 1;
    } else if (quotes.length > 5) {
        plainticks = quotes.length - 5;
    }
    if (plainticks > 0) {
        result.push(quotes.substring(0, plainticks));
    }
    // mw-quote token Will be consumed in token transforms
    var mwq = new SelfclosingTagTk( 'mw-quote', [],
        { tsr: [peg$reportedPos + plainticks, peg$currPos] } );
    mwq.value = quotes.substring(plainticks);
    result.push(mwq);
    return result;
}


/***********************************************************
 * Pre and xmlish tags
 ***********************************************************/

// Indented pre blocks differ from their non-indented (purely tag-based)
// cousins by having their contents parsed.
pre_indent
  = pre_indent_in_tags
  / l:pre_indent_line
    // keep consuming indented lines unless they start a table
    ls:(s:sol
        !(space* "{|")
        pl:pre_indent_line {
              return s.concat(pl);
        }
    )*
  {
      return l.concat(ls);
  }

pre_tag_name =
  tag:[prePRE]+ {
      tag = tag.join('');
      if (tag.toLowerCase() === "pre") {
          return tag;
      } else {
          peg$currPos = peg$reportedPos;
          return peg$FAILED;
      }
  }

space_generic_attributes
  = r:(space g:generic_attribute* { return g; })? {
    return r === null ? [] : r;
  }

// An indented pre block that is surrounded with pre tags. The pre tags are
// used directly.
// XXX gwicke: check if the first line is not indented, and round-trip spaces;
// possibly merge with the regular 'pre' production.
// FIXME: fix tag end position
pre_indent_in_tags
  = & { return stops.inc('pre'); }
    s:spaces // XXX: capture space for round-tripping
    "<" pre_tag_name
    attribs:space_generic_attributes
    ">"
    l:nested_block_line
    ls:(sol pre_indent_line)*
    "</" pre_tag_name ">"
  {
    stops.dec('pre');
    var ret = [ new TagTk( 'pre', attribs, { tsr: [peg$reportedPos, peg$reportedPos] } ) ];
    // ls will always be an array
    return ret.concat( l, tu.flattenIfArray( ls ), [ new EndTagTk( 'pre' ) ] );
  }
  / & { return stops.dec('pre'); }

// Don't recognize tabs
pre_indent_line = " " l:nested_block_line {
    //console.warn( JSON.stringify( [s, l] ) );
    return [' '].concat(l);
}

/*
 * Pre blocks defined using non-indented HTML tags only parse nowiki tags and
 * html entities inside them, and convert other content to verbatim text.
 * Nowiki inside pre is not functionally needed, but supported for backwards
 * compatibility.
 *
 * TODO: add entity support!
 */
pre
  = & { return stops.inc('pre'); }
    "<" pre_tag_name
    attribs:space_generic_attributes
    space*
    endpos:(">" { return peg$currPos; })
    // MediaWiki <pre> is special in that it converts all pre content to plain
    // text.
    ts:(    newlineToken
                / (htmlentity / [^&<]+)+
                / nowiki
                / !("</" pre_tag_name ">") t2:(htmlentity / .) { return t2; })*
    ("</" pre_tag_name ">" / eof) {
        stops.dec('pre');
        // return nowiki tags as well?

        // Emit as SelfclosingTag in order to avoid the nested pre problem in
        // the PreHandler.
        attribs.push(new KV('property', 'mw:html'));
        attribs.push(new KV('content', tu.flatten_stringlist(ts)));
        return [
            new SelfclosingTagTk('pre', attribs, {
                tsr: [peg$reportedPos, peg$currPos],
                endpos: endpos
            })
        ];

    }
  / "</" pre_tag_name ">" { stops.dec('pre'); return "</pre>"; }
  // if this is still preish, emit as a string
  // necessary to work with the pre_start lookaheads
  / p:('<' pre_tag_name space*) {
	  stops.dec('pre');
	  return tu.flatten_stringlist(p);
    }
  / & { return stops.dec('pre'); }

/* -----------------------------------------------------------------------
 * Extension tags should be parsed with higher priority than anything else.
 * The trick we use is to strip out the content inside a matching tag-pair
 * and not tokenize it. The content, if it needs to parsed (for example,
 * for <ref>, <*include*> tags), is parsed in a fresh tokenizer context
 * which means any error correction that needs to happen is restricted to
 * the scope of the extension content and doesn't spill over to the higher
 * level.  Ex: <math><!--foo</math>.
 *
 * This trick also lets us prevent extension content (that dont accept WT)
 * from being parsed as wikitext (Ex: <math>\frac{foo\frac{bar}}</math>)
 * We dont want the "}}" being treated as a template closing tag and closing
 * outer templates.
 * ----------------------------------------------------------------------- */

xmlish_tag =
    t2:(t:generic_tag {
        var tagName = t.name.toLowerCase(),
            dp = t.dataAttribs,
            isHtmlTag = Util.isHTMLElementName(tagName),
            isInstalledExt = options.env.conf.wiki.isExtensionTag(tagName),
            isIncludeTag = tagName === 'includeonly'
                            || tagName === 'noinclude'
                            || tagName === 'onlyinclude';

        if (!isHtmlTag && !isInstalledExt && !isIncludeTag) {
            return Util.newlinesToNlTks(input.substring(dp.tsr[0], dp.tsr[1]), dp.tsr[0]);
        }

        if (t.constructor !== EndTagTk && !isHtmlTag) {
            if (t.constructor === TagTk) {
                var tsr0 = dp.tsr[0],
                    endTagRE = new RegExp("^(?:.|\n)*?(</\\s*" + tagName + "\\s*>)", "mi"),
                    restOfInput = input.substring(tsr0),
                    tagContent = restOfInput.match(endTagRE),
                    extSrc = null,
                    tagWidths = null,
                    endTagWidth = 0;

                if (tagContent) {
                    extSrc = tagContent[0];
                    endTagWidth = tagContent[1].length;

                    if (tagName === 'ref') {
                        // Support 1-level nesting of <ref> tags during tokenizing.
                        // <ref> tags are the exception to the rule (no nesting of ext tags)
                        //
                        // Expand extSrc as long as there is a <ref> tag found in the
                        // extension source body.
                        var s = extSrc.substring(peg$currPos-tsr0);
                        while (s && s.match(new RegExp("<" + tagName + "[^<>]*>"))) {
                            tagContent = restOfInput.substring(extSrc.length).match(endTagRE);
                            if (tagContent) {
                                s = tagContent[0];
                                endTagWidth = tagContent[1].length;
                                extSrc += s;
                            } else {
                                s = null;
                            }
                        }
                    }
                } else {
                    // We accept unclosed references tags,
                    // as does the PHP parser. They will normalize
                    // to self-closed in a round trip.
                    if ( tagName === 'references' ) {
                        dp.src = input.substring(dp.tsr[0], dp.tsr[1]);
                        dp.origInput = input;
                        dp.extLikeTag = true;
                        dp.isInstalledExt = isInstalledExt;
                        dp.isIncludeTag = isIncludeTag;
                        dp.tagWidths = [dp.tsr[1] - dp.tsr[0], 0];
                        dp.skipLen = 0;
                    }
                    return t;
                }

                if (extSrc) {
                    tagWidths = [peg$currPos-tsr0, endTagWidth];
                    var extContentLen = extSrc.length - tagWidths[0] - tagWidths[1];

                    // If the xml-tag is a known installed (not native) extension,
                    // skip the end-tag as well.
                    var skipLen = extContentLen;
                    if (isInstalledExt && !isIncludeTag) {
                        skipLen += endTagWidth;
                    }

                    // Extension content source
                    dp.src = extSrc;
                    dp.origInput = input;

                    // Replace extension content (and possibly the end tag, as well) with
                    // dummy content so it matches the rule following this match and
                    // can be tokenized independently (if required).  This is just a trick
                    // to tokenize ref content with higher priority.
                    //
                    // However, if there is a legitimate # char after the end-tag in the
                    // original text, we need to pick a different char if the char following
                    // the end-tag is a '#'!
                    //    Ex: <ref>foo</ref>#bar
                    // Admittedly a rare use case, but we need a robust fix.

                    var skipChar = '#';
                    if (input.length >= peg$currPos+skipLen && input[peg$currPos+skipLen] === '#') {
                        skipChar = '_';
                    }
                    input = input.slice(0,peg$currPos) +
                        Util.charSequence('', skipChar, skipLen) +
                        input.slice(peg$currPos+skipLen);

                    // Temporary state
                    dp.extLikeTag = true;
                    dp.isInstalledExt = isInstalledExt;
                    dp.isIncludeTag = isIncludeTag;
                    dp.skipLen = skipLen;
                    dp.tagWidths = tagWidths;
                    dp.skipChar = skipChar;

                    // console.warn("input: " + input);
                }
            } else {
                // SelfclosingTagTk
                dp.src = input.substring(dp.tsr[0], dp.tsr[1]);
                if (isInstalledExt) {
                    dp.extLikeTag = true;
                    dp.isInstalledExt = isInstalledExt;
                    dp.skipLen = 0;
                    dp.tagWidths = [dp.tsr[1] - dp.tsr[0], 0];
                    dp.origInput = input;
                }
            }
        }

        currExtTag = t;
        // console.warn("curr: " + JSON.stringify(currExtTag));
        return t;
    }) (
      dummyText:('#'+ / '_'+) {
        // Should only match if currExtTag is an extension
        // with a non-zero skip-length
        //
        // Ex: <ref>foo</ref>, <ref>foo</ref>#bar, <ref>foo</ref>_bar
        var dp = currExtTag ? currExtTag.dataAttribs : null;
        if (dp &&
            dp.extLikeTag &&
            dummyText.length === dp.skipLen &&
            dummyText[0] === dp.skipChar) {
            return true;
         } else {
            peg$currPos = peg$reportedPos;
            return peg$FAILED;
         }
      }
      / &  {
        // Should not match if currExtTag is an extension
        // or is an extension tag with a zero skip length
        //
        // Ex: <ref />foo, <ref />#foo, <ref />_foo
        return (!currExtTag ||
            !currExtTag.dataAttribs.extLikeTag ||
            currExtTag.dataAttribs.skipLen === 0);
      }
    ) {
        if ( Array.isArray(t2) ) {
            return t2;
        }

        var ret = t2,
            dp = t2.dataAttribs;
        if (dp.extLikeTag) {
            var tagName = t2.name.toLowerCase();
            if (dp.isInstalledExt && !dp.isIncludeTag) {
                // update tsr[1] to span the start and end tags.
                dp.tsr[1] = peg$currPos;
                ret = new SelfclosingTagTk('extension', [
                    new KV('typeof', 'mw:Extension'),
                    new KV('name', tagName),
                    new KV('about', options.env.newAboutId()),
                    new KV('source', dp.src),
                    new KV('options', t2.attribs)
                ], dp);
            } else {
                // If not a known installed extension, parse content as wikitext.
                // - include-directives: <noinclude>, <includeonly>, ...
                // - a non-html5 tag like <big>
                // Parse ext-content, strip eof, and shift tsr
                var extContent = dp.src.substring(dp.tagWidths[0], dp.src.length - dp.tagWidths[1]);
                var extContentToks = (new PegTokenizer(options.env)).tokenize(extContent);
                if (dp.tagWidths[1] > 0) {
                    extContentToks = Util.stripEOFTkfromTokens(extContentToks);
                }
                Util.shiftTokenTSR(extContentToks, dp.tsr[0] + dp.tagWidths[0]);
                ret = [t2].concat(extContentToks);
            }

            // Reset input
            input = dp.origInput;

            // Clear temporary state
            dp.extLikeTag = undefined;
            dp.skipChar = undefined;
            dp.skipLen = undefined;
            dp.isInstalledExt = undefined;
            dp.isIncludeTag = undefined;
            dp.origInput = undefined;
        }
        // console.warn("RET: " + JSON.stringify(ret));

        currExtTag = null;

        return ret;
    }

/*
 * Nowiki treats anything inside it as plain text. It could thus also be
 * defined as an extension that returns its raw input text, possibly wrapped
 * in a span for round-trip information. The special treatment for nowiki in
 * pre blocks would still remain in the grammar though, so overall handling it
 * all here is cleaner.
 */

nowiki_tag_name =
  tag:[nowikNOWIK]+ {
      tag = tag.join('');
      if (tag.toLowerCase() === "nowiki") {
          return tag;
      } else {
          peg$currPos = peg$reportedPos;
          return peg$FAILED;
      }
  }

nowiki
  = "<" nowiki_tag_name space* ">"
    startTagEndPos:({return peg$currPos;})
    nc:nowiki_content
    endTagStartPos:({return peg$currPos;})
    "</" nowiki_tag_name space* ">" {
        // console.warn( 'full nowiki return: ' + pp(nc));
        return [
            new TagTk( 'span',
                    [
                        {k: 'typeof', v: 'mw:Nowiki'}
                    ],
                    { tsr: [peg$reportedPos, startTagEndPos] } )
        ].concat( nc, [
                    new EndTagTk( 'span',
                    [
                        {k: 'typeof', v: 'mw:Nowiki'}
                    ],
                    { tsr: [endTagStartPos, peg$currPos] })
                ] );
    }
  // nowiki fallback: source-based round-tripping of <nowiki />.
  / nw0:({return peg$currPos;})
    "<" nowiki_tag_name space* "/" space* ">" {
      // console.warn('<nowiki/>');
      return [
          new SelfclosingTagTk('meta',
                  [new KV('typeof', 'mw:Placeholder')],
                  {
                      src: input.substring(nw0, peg$currPos),
                      tsr: [nw0, peg$currPos]
                  })
        ];
    }
  // nowiki fallback: source-based round-tripping
  // of unbalanced nowiki tags that are treated as text.
  / ! { return stops.counters.pre > 0; }
    nw0:({return peg$currPos;})
    "<" "/"? nowiki_tag_name space* "/"? space* ">" {
      // console.warn('nowiki text');
      var nowiki = input.substring(nw0, peg$currPos);
      return [
            new TagTk( 'span', [ new KV( 'typeof', 'mw:Placeholder' ) ], {
                src: nowiki,
                tsr: [nw0, nw0]
            } ),
            nowiki,
            new EndTagTk( 'span', [], { tsr: [peg$currPos, peg$currPos] } )
      ];
    }

// Should abort the nowiki match:
//   <pre><nowiki></pre></nowiki>
// Should allow the </pre> in nowiki:
//   <nowiki></pre></nowiki>
pre_break = & "</pre>" {
    //console.log( stops.counters );
    return stops.counters.pre > 0 ? undefined : peg$FAILED;
}

nowiki_content
  = ts:(   (htmlentity / [^&<]+)+
           / "<pre" p0:optionalSpaceToken p1:[^>]* ">" p2:nowiki_content "</pre>" {
                 //console.warn('nested pre in nowiki');
                 return ["<pre"].concat(p0, p1, [">"], p2, ["</pre>"]).join('');
               }
           / (!pre_break !("</" nowiki_tag_name space* ">") c:(htmlentity / .) {
               //console.warn('nowiki: single char' + c);
               return c;
           })
       )* {
            // return nowiki tags as well?
            //console.warn('nowiki_content: return' + pp(ts));
            return tu.flatten_stringlist(ts);
          }

/* Generic XML-like tags
 *
 * These also cover extensions (including Cite), which will hook into the
 * token stream for further processing. The content of extension tags is
 * parsed as regular inline, but the source positions of the tag are added
 * to allow reconstructing the unparsed text from the input. */

// See http://dev.w3.org/html5/spec/Overview.html#syntax-tag-name and
// following paragraphs
generic_tag
  = "<"
    end:"/"? name:[0-9a-zA-Z]+
    attribs:generic_newline_attribute*
    space_or_newline* // No need to preserve this -- canonicalize on RT via dirty diff
    selfclose:"/"?
    bad_ws:space* // No need to preserve this -- canonicalize on RT via dirty diff
    ">" {
        name = name.join('');
        var lcName = name.toLowerCase(),
            isVoidElt = Util.isVoidElement( lcName ) ? true : null;
        // Support </br>
        var broken = false;
        if (lcName === 'br' && end) {
            broken = true;
            end = null;
        }

        var res = tu.buildXMLTag(name, lcName, attribs, end, selfclose || isVoidElt, [peg$reportedPos, peg$currPos]);

        // change up data-attribs in one scenario
        // void-elts that aren't self-closed ==> useful for accurate RT-ing
        if (selfclose === null && isVoidElt) {
            res.dataAttribs.selfClose = undefined;
            res.dataAttribs.noClose = true;
        }
        if (broken || bad_ws.length > 0) {
            res.dataAttribs.brokenHTMLTag = true;
        }
        return res;
    }

could_be_attribute =
    // quick sanity check before expensive attribute_preprocessor_text_line
    // production. Also try to parse on [|!+;] for now which seem to be common
    // syntax errors in production that hidden by the PHP parser (by stripping
    // the 'attributes').
    space* ([a-zA-Z|!+;] /
            // Crude heuristic that just excludes attribute-less row-syntax
            // table cells like this with simple (pipe-less) values: |a||b||c
            [^\'\"\n|]+ '|' [^|\n] /
            // Possibly a templated attribute
            '{{' [^}]+ '}'  /
            // comment or noincludes
            '<' ('!--' / 'noinclude' / 'onlyinclude' / 'includeonly'))

// A generic attribute that can span multiple lines.
generic_newline_attribute
  = s:space_or_newline+
    namePos0:({return peg$currPos;})
    name:generic_attribute_name
    namePos:({return peg$currPos;})
    valueData:( space_or_newline*
        v:generic_attribute_newline_value { return v; })?
{
    //console.warn('generic_newline_attribute: ' + pp( name ))
    var res;

    // Encapsulate protected attributes.
    if ( typeof name === "string" ) {
        name = name.replace(
            /^(about|data-parsoid.*|data-x.*|property|rel|typeof)$/i,
            "data-x-$1" );
    }

    if ( valueData !== null ) {
        var value = valueData.value;
        res = new KV( name, value );
        res.vsrc = valueData.valueSrc;
    } else {
        res = new KV( name, '' );
    }
    if ( Array.isArray(name) ) {
        res.ksrc = input.substring( namePos0, namePos );
    }
    return res;
}

// A single-line attribute.
generic_attribute
  = s:optionalSpaceToken
    namePos0:({return peg$currPos;})
    name:generic_attribute_name
    namePos:({return peg$currPos;})
    valueData:(optionalSpaceToken
        // attribute value
        v:("=" v:(space* vv:att_value { return vv; })? {
            return v === null ? [] : v;
        }) { return v; }
    )?
{
    //console.warn( 'generic attribute: ' + pp([name, value]));
    // FIXME: name might just be a template, which can expand to a key-value
    // pair later. We'll need to handle that in the AttributeTransformManager.
    var res;
    if ( valueData !== null ) {
        var value = valueData.value;
        res = new KV( name, value );
        res.vsrc = valueData.valueSrc;
    } else {
        res = new KV( name, '' );
    }
    if ( Array.isArray(name) ) {
        res.ksrc = input.substring( namePos0, namePos );
    }
    return res;
}

// ( Replaced by generic_attribute_name for template / parameter support. )
//// http://dev.w3.org/html5/spec/Overview.html#attributes-0, and we also
//// disallow newlines, | and {.
//generic_attribute_plain_name
//  = n:[^ \t\0/"'>=\n|{]+ {
//        return n.join('');
//  }

// Also eat these chars in a wikitext table or tr attribute name. They are
// normally not matched by the attribute_preprocessor_text_line.
broken_table_attribute_name_char = c:[ \t>\[] { return new KV(c, ''); }

generic_attribute_name
  = & { return stops.push( 'equal', true ); }
    name:attribute_preprocessor_text_line
    {
        stops.pop( 'equal' );
        //console.warn( 'generic attribute name: ' + pp( name ) );
        return name;
    }
  / & { return stops.pop( 'equal' ); }

// A generic attribute, possibly spanning multiple lines.
generic_attribute_newline_value
  = "=" v:( space_or_newline* vv:xml_att_value { return vv; })? {
      return v === null ? [] : v;
  }
// A generic but single-line attribute.
generic_attribute_value
  = "=" v:(space* vv:att_value { return vv; })? {
      return v === null ? [] : v;
  }

// Attribute value, quoted variants can span multiple lines.
xml_att_value
  = "'" r:(valPos1:({return peg$currPos;}) t1:attribute_preprocessor_text_single? valPos2:({return peg$currPos;}) "'"
            { return tu.get_attribute_value_and_source(input, t1, valPos1, valPos2); }
        // Missing end quote: accept | and > look-ahead as heuristic
        / valPos1:({return peg$currPos;}) t2:attribute_preprocessor_text_single_broken? valPos2:({return peg$currPos;}) &[|>]
            { return tu.get_attribute_value_and_source(input, t2, valPos1, valPos2); } )
                { return r; }
  / '"' r:(valPos1:({return peg$currPos;}) t1:attribute_preprocessor_text_double? valPos2:({return peg$currPos;}) '"'
            { return tu.get_attribute_value_and_source(input, t1, valPos1, valPos2); }
        // Missing end quote: accept | and > look-ahead as heuristic
        / valPos1:({return peg$currPos;}) t2:attribute_preprocessor_text_double_broken? valPos2:({return peg$currPos;}) &[|>]
            { return tu.get_attribute_value_and_source(input, t2, valPos1, valPos2); } )
                { return r; }
  / valPos1:({return peg$currPos;}) t:attribute_preprocessor_text? valPos2:({return peg$currPos;})
        { return tu.get_attribute_value_and_source(input, t, valPos1, valPos2); }

// Attribute value, restricted to a single line.
att_value
  = "'" r:(valPos1:({return peg$currPos;}) t1:attribute_preprocessor_text_single_line? valPos2:({return peg$currPos;}) ("'" / &"\n")
            { return tu.get_attribute_value_and_source(input, t1, valPos1, valPos2); }
        // Missing end quote: accept | and > look-ahead as heuristic
        / valPos1:({return peg$currPos;}) t2:attribute_preprocessor_text_single_line_broken? valPos2:({return peg$currPos;}) &[|>]
            { return tu.get_attribute_value_and_source(input, t2, valPos1, valPos2); } )
                { return r; }
  / '"' r:(valPos1:({return peg$currPos;}) t1:attribute_preprocessor_text_double_line? valPos2:({return peg$currPos;}) ('"' / &"\n")
            { return tu.get_attribute_value_and_source(input, t1, valPos1, valPos2); }
        // Missing end quote: accept | and > look-ahead as heuristic
        / valPos1:({return peg$currPos;}) t2:attribute_preprocessor_text_double_line_broken? valPos2:({return peg$currPos;}) &[|>]
            { return tu.get_attribute_value_and_source(input, t2, valPos1, valPos2); } )
                { return r; }
  / valPos1:({return peg$currPos;}) t:attribute_preprocessor_text_line? valPos2:({return peg$currPos;})
        { return tu.get_attribute_value_and_source(input, t, valPos1, valPos2); }

/*
 * A variant of generic_tag, but also checks if the tag name is a block-level
 * tag as defined in
 * http://dev.w3.org/html5/spec/Overview.html#syntax-tag-name and following
 * paragraphs.
 */
block_tag
  = "<" end:"/"?
    name:(cs:[a-zA-Z]+ { return cs.join(''); })
    attribs:generic_newline_attribute*
    space_or_newline*
    selfclose:"/"?
    ">" {
        var lcName = name.toLowerCase();
        if (lcName !== "pre" && lcName !== "hr" &&
            constants.HTML.BlockTags.has(name.toUpperCase())
        ) {
            return [tu.buildXMLTag(name, lcName, attribs, end, selfclose, [peg$reportedPos, peg$currPos])];
        } else {
            // abort match if tag is not block-level
            peg$currPos = peg$reportedPos;
            return peg$FAILED;
        }
    }


/*********************************************************
 *   Lists
 *********************************************************/
lists = (dtdd / hacky_dl_uses / li) (sol (dtdd / hacky_dl_uses / li))*

li = bullets:list_char+
     c:nested_block_line
     &eolf
{
    if ( c === null ) {
        c = [];
    }
    // Leave bullets as an array -- list handler expects this
    var li = new TagTk( 'listItem', [], { tsr: [peg$reportedPos, peg$reportedPos + bullets.length] }  );
    li.bullets = bullets;
    return [ li, c ];
}

/*
 * This production is required to support wikitext of this form
 *   ::{|border="1"|foo|bar|baz|}
 * where the leading colons are used to indent the entire table.
 * This hack was added back in 2006 in commit
 * a0746946312b0f1eda30a2c793f5f7052e8e5f3a based on a patch by Carl
 * Fürstenberg.
 */
hacky_dl_uses = bullets:":"+
               c:table_lines
               s:space* // Do we really need to RT this?
               &comment_space_eolf
{
    // Leave bullets as an array -- list handler expects this
    var li = new TagTk( 'listItem', [], { tsr: [peg$reportedPos, peg$reportedPos + bullets.length] }  );
    li.bullets = bullets;
    return tu.flattenIfArray([li, c || [], s || []]);
}

dtdd
  = bullets:(!(";" !list_char) lc:list_char { return lc; })*
    ";"
    & {return stops.inc('colon');}
    c:nested_block_line
    cpos:(":" { return peg$currPos; })
    // Fortunately dtdds cannot be nested, so we can simply set the flag
    // back to 0 to disable it.
    & { stops.counters.colon = 0; return true;}
    d:nested_block_line?
    &eolf {
        // Leave bullets as an array -- list handler expects this
        // TSR: +1 for the leading ";"
        var numBullets = bullets.length + 1;
        var li1 = new TagTk( 'listItem', [], { tsr: [peg$reportedPos, peg$reportedPos + numBullets] } );
        li1.bullets = bullets.slice();
        li1.bullets.push(";");
        // TSR: -1 for the intermediate ":"
        var li2 = new TagTk( 'listItem', [], { tsr: [cpos-1, cpos], stx: 'row' } );
        li2.bullets = bullets.slice();
        li2.bullets.push(":");

        return [ li1 ].concat( c, [ li2 ], d || [] );
    }
  // Fall-back case to clear the colon flag
  / & { stops.counters.colon = 0; return false; }


list_char = [*#:;]



/*********************************************************************
 * Tables
 *
 * Table productions are geared to support independent parsing of fragments in
 * templates (the common table start / row / table end use case). The tokens
 * produced by these fragments then match up to a table while building the
 * DOM tree. For similar reasons, table rows do not emit explicit end tag
 * tokens.
 *
 * The separate table_lines production is faster than moving those productions
 * directly to block_lines.
 *********************************************************************/

table_lines
  = //& { console.warn('enter table_lines: ' + input.substr(peg$currPos, 20)); return true; }
    (! inline_breaks / & '{{!}}' )
    r:(
        & { return stops.push('table', true); }
        tl:table_line
        tls:(
            nls:optionalNewlines
            s:sol
            tl2:table_line { return nls.concat(s, tl2); }
        )*
        {
            stops.pop('table');
            //console.warn('table_lines: ' + pp(tl.concat(tls)));
            return tl.concat( tls );
        }
      / & { return stops.pop('table'); }
    ) { return r; }

// This production assumes start-of-line position!
table_line
  = (space / comment)* (table_start_tag
  / table_heading_tags
  / table_row_tag
  / table_data_tags
  / table_caption_tag
  / table_end_tag)


table_start_tag
  = b:"{" p:pipe
    // ok to normalize away stray |} on rt (see bug 57360)
    & { return stops.push('table', false); }
    ta:(generic_attribute / broken_table_attribute_name_char)*
    tsEndPos:({stops.pop('table'); return peg$currPos;})
    {
        var tblStart = new TagTk( 'table', [], { tsr: [peg$reportedPos, tsEndPos] } );
        if (p !== "|") {
            // Variation form default
            // "<brace-char>"+p is triggering some bug in pegJS
            // I cannot even use that expression in the comment!
            tblStart.dataAttribs.startTagSrc = b+p;
        }
        if ( ta ) {
            tblStart.attribs = ta;
        }

        return [tblStart];
    }

table_caption_tag
    // avoid recursion via nested_block_in_table
  = ! { return stops.onStack('tableDataBlock'); }
    p:pipe "+"
    args:single_cell_table_args?
    tagEndPos:({return peg$currPos;})
    c:nested_block_in_table* {
        return tu.buildTableTokens("caption", "|+", args, [peg$reportedPos, tagEndPos], peg$currPos, c)
            .concat([new EndTagTk('caption')]);
    }


table_row_tag
  = //& { console.warn("table row enter @" + input.substr(peg$currPos, 30)); return true; }
    // avoid recursion via nested_block_in_table
    ! { return stops.onStack('tableDataBlock'); }
    p:pipe dashes:"-"+
    & { return stops.push('table', false); }
    a:(generic_attribute / broken_table_attribute_name_char)*
    tagEndPos:({stops.pop('table'); return peg$currPos;})
    // handle tables with missing table cells after a row
    td:implicit_table_data_tag?
    {
        // We rely on our tree builder to close the row as needed. This is
        // needed to support building tables from fragment templates with
        // individual cells or rows.
        var trToken = new TagTk( 'tr', a, { tsr: [peg$reportedPos, tagEndPos], startTagSrc: p + dashes.join('') } );
        var res;
        if ( !td ) {
            res = [trToken];
        } else {
            //console.warn( 'tr result: ' + pp(trToken.concat(td)) + ' stops: ' + pp(stops));
            res = [trToken].concat(td);
        }
        return res;
    }

table_data_tags
    // avoid recursion via nested_block_in_table
  = ! { return stops.onStack('tableDataBlock'); }
    p:pipe
    ![+-] td:table_data_tag
    tagEndPos:({return peg$currPos;})
    tds:( pp:(pipe_pipe / p:pipe & row_syntax_table_args { return p; })
            tdt:table_data_tag {
            var da = tdt[0].dataAttribs;
            da.stx_v = "row";
            da.tsr[0] = da.tsr[0] - pp.length; // include "||"
            if (pp !== "||" || (da.startTagSrc && da.startTagSrc !== pp)) {
                // Variation from default
                da.startTagSrc = pp + (da.startTagSrc ? da.startTagSrc.substring(1) : '');
            }
            return tdt;
        }
    )* {
        var da = td[0].dataAttribs;
        da.tsr[0] = da.tsr[0] - p.length; // include "|"
        if (p !== "|") {
            // Variation from default
            da.startTagSrc = p;
        }
        return td.concat(tds);
    }

implicit_table_data_tag
  = & sol // Implicit table data tag added only when content starts on a newline
    !( sol+ (pipe / [!+-]) )
    ! "}"
    tagEndPos:({return peg$currPos;})
    b:nested_block+
    {
        b = tu.flattenIfArray(b);
        var nlTok = b.shift();
        var td = tu.buildTableTokens("td", "|", '', [nlTok.dataAttribs.tsr[1], tagEndPos], peg$currPos, b);
        td[0].dataAttribs.autoInsertedStart = true;
        td[0].dataAttribs.autoInsertedEnd = true;
        return [nlTok, td];
    }

table_data_tag
  = //& { dp("table_data enter, pos=" + peg$currPos + input.substr(peg$currPos,10)); return true; }
    ! "}"
    arg:row_syntax_table_args?
    //& { console.warn("past attrib, pos=" + peg$currPos + input.substr(peg$currPos,10)); return true; }
    // use inline_breaks to break on tr etc
    tagEndPos:({return peg$currPos;})
    td:nested_block_in_table*
    {
        return tu.buildTableTokens("td", "|", arg, [peg$reportedPos, tagEndPos], peg$currPos, td);
    }

table_heading_tags
  = //& { console.warn( 'th enter @' + input.substr(peg$currPos, 10)); return true; }
    "!"
    th:table_heading_tag
    ths:( pp:("!!" / pipe_pipe) tht:table_heading_tag {
            var da = tht[0].dataAttribs;
            da.stx_v = 'row';
            da.tsr[0] = da.tsr[0] - pp.length; // include "!!" or "||"

            if (pp !== "!!" || (da.startTagSrc && da.startTagSrc !== pp)) {
                // Variation from default
                da.startTagSrc = pp + (da.startTagSrc ? da.startTagSrc.substring(1) : '');
            }
            return tht;
          }
    )* {
        //console.warn( 'thts: ' + pp([th, ths]));
        th[0].dataAttribs.tsr[0]--; // include "!"
        return th.concat(ths);
    }

table_heading_tag
  = & { return stops.push('th', true); }
    arg:row_syntax_table_args?
    tagEndPos:({return peg$currPos;})
    c:nested_block_in_table* {
        stops.pop('th');
        //console.warn( 'table_heading_tag: ' + pp( [a, c] ) );
        return tu.buildTableTokens("th", "!", arg, [peg$reportedPos, tagEndPos], peg$currPos, c);
    }
    / & { return stops.pop('th'); }

table_end_tag
  = space* p:pipe b:"}" {
      var tblEnd = new EndTagTk( 'table', [], { tsr: [peg$reportedPos, peg$currPos] } );
      if (p !== "|") {
          // p+"<brace-char>" is triggering some bug in pegJS
          // I cannot even use that expression in the comment!
          tblEnd.dataAttribs.endTagSrc = p+b;
      }
      return [ tblEnd ];
  }

/**
 * Table parameters separated from the content by a single pipe. Matches even
 * if there are more pipes following.
 */
single_cell_table_args
  = & { return stops.push('pipe', true); }
    as:generic_attribute* s:space* p:pipe {
        stops.pop('pipe');
        //console.warn( 'tcargs' + JSON.stringify( as ) + " stops: " + pp(stops) );
        return [as, s, p];
    }
    / & { return stops.pop('pipe'); }

/**
 * Table parameters separated from the content by a single pipe. Does *not*
 * match if followed by double pipe (row-based syntax).
 */
row_syntax_table_args
  = & { return stops.inc('tableCellArg'); }
    & could_be_attribute
    as:generic_attribute* s:space* p:pipe !pipe {
        stops.dec('tableCellArg');
        //console.warn( 'tcargs' + JSON.stringify( as ) + " stops: " + pp(stops) );
        return [as, s, p];
    }
    / & { return stops.dec('tableCellArg'); }


/*******************************************************************
 * Text variants and other general productions
 *******************************************************************/

/* All chars that cannot start syntactic structures in the middle of a line
 * XXX: ] and other end delimiters should probably only be activated inside
 * structures to avoid unnecessarily leaving the text production on plain
 * content.
 *
 * TODO: Much of this is should really be context-dependent (syntactic
 * flags). The wikilink_preprocessor_text production is an example where
 * text_char is not quite right and had to be augmented. Try to minimize /
 * clarify this carefully!
 */

text_char = [^'<~[{\n\r:\]}|!=]

/* Legend
 * '    quotes (italic/bold)
 * <    start of xmlish_tag
 * ~    signatures/dates
 * [    start of links
 * {    start of parser functions, transclusion and template args
 * \n   all sort of block-level markup at start of line
 * \r   ditto
 * h    http(s) urls
 * n    nntp(s) urls
 * m    mailto urls
 * I    start of ISBN 10/13 auto links
 * P    start of PMID auto links
 * R    start of RFC auto links
 *
 * _    behavior switches (e.g., '__NOTOC__') (XXX: not URL related)
 * ! and | table cell delimiters, might be better to specialize those
 * =    headings - also specialize those!
 *
 * The following chars are also included for now, but only apply in some
 * contexts and should probably be enabled only in those:
 * :    separate definition in ; term : definition
 * ]    end of link
 * }    end of parser func/transclusion/template arg
 */

urltext = ( t:[^'<~[{\n\pPrRfFgGhHiImMnNsStTwW_|!:\]} &=]+ { return t.join(''); }
          / & [/fFgGhHiImMnNsStTwWIPR] al:autolink { return al; }
          / & "&" he:htmlentity { return he; }
          // Convert trailing space into &nbsp;
          // XXX: This should be moved to a serializer
          // This is a hack to force a whitespace display before the colon
          / ' ' & ':' {
              return [
                  new TagTk( 'span', [ new KV( 'typeof', 'mw:Placeholder' ) ], { src: ' ', tsr: [peg$reportedPos, peg$reportedPos], isDisplayHack: true } ),
                  "\u00a0",
                  new EndTagTk( 'span', [], { tsr: [peg$currPos, peg$currPos] } )
              ];
          }
          / & ('__') bs:behavior_switch { return bs; }
          // / t:text_char
          // Inline copy of text_char for performance, as about 96% of
          // text_char calls originate here.
          // Keep in sync and/or remove after upgrading to pegjs 0.8 which
          // inlines simple productions like these automatically.
          / [^'<~[{\n\r:\]}|!=] )+

/*
    '//', // for protocol-relative URLs, but not in text!
    'ftp://',
    'git://',
    'gopher://',
    'http://',
    'https://',
    'irc://',
    'ircs://',  // @bug 28503
    'mailto:',
    'mms://',
    'news:',
    'nntp://', // @bug 3808 RFC 1738
    'svn://',
    'telnet://', // Well if we're going to support the above.. -ævar
    'worldwind://',
*/

// Old version
//text = t:[A-Za-z0-9,._ "?!\t-]+ { return t.join('') }

htmlentity = "&" c:[#0-9a-zA-Z]+ ";" {
    //return "&" + c.join('') + ";";
    var m = "&" + c.join('') + ";",
        cc = Util.decodeEntities(m);
    // if this is an invalid entity, don't tag it with 'mw:Entity'
    if (cc.length > 2 /* decoded entity would be 1 or 2 UTF-16 characters */) {
        return cc;
    }
    return [
        new TagTk('span', [new KV('typeof', 'mw:Entity')], { src: m, srcContent: cc, tsr: [peg$reportedPos, peg$reportedPos] } ),
        cc,
        new EndTagTk('span', [], { tsr: [peg$currPos,peg$currPos] })
    ];
}

spaces
  = s:[ \t]+ { return s.join(''); }

space = [ \t]

optionalSpaceToken
  = s:space* {
      if ( s.length ) {
          return [s.join('')];
      } else {
          return [];
      }
  }

/* This production corresponds to \s in the PHP preg_* functions,
 * which is used frequently in the PHP parser.  The inclusion of
 * form feed (but not other whitespace, like vertical tab) is a quirk
 * of Perl, which PHP inherited via the PCRE (Perl-Compatible Regular
 * Expressions) library.
 */
space_or_newline
  = [ \t\n\r\x0c]

/* This production corresponds to \b in the PHP preg_* functions,
 * after a word character.  That is, it's a zero-width lookahead that
 * the next character is not a word character.
 */
end_of_word
  = eof / ! [A-Za-z0-9_] { return ''; }

// Extra newlines followed by at least another newline. Usually used to
// compress surplus newlines into a meta tag, so that they don't trigger
// paragraphs.
optionalNewlines
  = spc:(n:[\n\r\t ] &([\n\r]) { return n; })* {
        if ( spc.length ) {
            return [spc.join('')];
        } else {
            return [];
        }
    }

sol = (empty_line_with_comments / sol_prefix) sol_rest

sol_prefix
  = newlineToken
  / & {
      // Use saved sol-state only at start of input
      // If we have saved state of not being in sol posn, fail the production
      // NOTE: Explicitly check for 'false' and not a falsy value
      return peg$currPos === 0 && options.pegTokenizer.savedSOL !== false;
  } { return []; }

sol_rest =
    // Eat multi-line comment, so that syntax after still matches as if it
    // was actually preceded by a newline
    cn:( c:comment n:newlineToken? {
              if ( n !== null ) {
                  return [c, n];
              } else {
                  return [c];
              }
          }
    )*
    // Eat <*include*> section at start of line, so that start-of-line
    // syntax after it still matches
    ni:( niStart:({return peg$currPos;})
         s:space*
        "<" c:"/"? t:include_limits
        ">" {return [s.join(''), c, t, [niStart, peg$currPos]];} )?
    {
        var niToken = [];
        if ( ni !== null ) {
            if ( ni[1] === '/' ) {
                niToken = [new EndTagTk( ni[2], [], { tsr: ni[3] } )];
            } else {
                niToken = [new TagTk( ni[2], [], { tsr: ni[3] } )];
            }
        }

        if ( cn === null ) {
            cn = [];
        }

        return cn.concat(niToken);
    }

empty_line_with_comments
  = sp:sol_prefix p:({return peg$currPos;}) c:(space* comment (space / comment)* newline)+ {
        return [
            sp,
            new SelfclosingTagTk("meta", [new KV('typeof', 'mw:EmptyLine')], {
                tokens: tu.flattenIfArray(c),
                tsr: [p, peg$currPos]
            })
        ];
    }

comment_space = comment / space
nl_comment_space = newline / comment_space

/**
 * noinclude / includeonly / onlyinclude productions. These are normally
 * handled by the generic_tag production, except where generic tags are not
 * allowed- for example in directives, which are allowed in various attribute
 * names and -values.
 *
 * Example test case:
 * {|
 * |-<includeonly>
 * foo
 * </includeonly>
 * |Hello
 * |}
 */

include_limits =
  "</" name:[0-9a-zA-Z]+ space_or_newline* ">" {
     // End tag only
     name = name.join('');
     var incl = name.toLowerCase();
     if (incl === "noinclude" || incl === "onlyinclude" || incl === "includeonly") {
         var dp = {tsr: [peg$reportedPos, peg$currPos]};
         // Record variant since tag is not in normalized lower case
         if (name !== incl) {
             dp.srcTagName = name;
         }
         return new EndTagTk(name, [], dp);
     } else {
         peg$currPos = peg$reportedPos;
         return peg$FAILED;
     }
  }
  / inclTag:("<" name:[0-9a-zA-Z]+ space_or_newline* ">" {
     // Start tag only
     name = name.join('');
     var incl = name.toLowerCase();
     if (incl === "noinclude" || incl === "onlyinclude" || incl === "includeonly") {
         var dp = {tsr: [peg$reportedPos, peg$currPos]},
             restOfInput = input.substring(peg$reportedPos),
             tagContent = restOfInput.match(new RegExp("^(.|\n)*?(</\\s*" + incl + "\\s*>)", "m"));

         if (!tagContent) {
            peg$currPos = peg$reportedPos;
            return peg$FAILED;
         }

         var tagWidths = [peg$currPos-peg$reportedPos, (tagContent ? tagContent[2].length : 0)],
             inclSrc = tagContent ? tagContent[0] : restOfInput,
             inclContentLen = inclSrc.length - tagWidths[0] - tagWidths[1],
             skipLen = inclContentLen;

         dp.src = inclSrc;
         dp.origInput = input;

         // Replace incl-content with '#' or '_'
         var skipChar = '#';
         if (input.length >= peg$currPos+skipLen && input[peg$currPos+skipLen] === '#') {
             skipChar = '_';
         }
         input = input.slice(0,peg$currPos) +
             Util.charSequence('', skipChar, skipLen) +
             input.slice(peg$currPos+skipLen);

         // Temporary state
         dp.skipLen = skipLen;
         dp.tagWidths = tagWidths;
         dp.skipChar = skipChar;

         // Record variant since tag is not in normalized lower case
         if (name !== incl) {
             dp.srcTagName = name;
         }

         return new TagTk(name, [], dp);
     } else {
         peg$currPos = peg$reportedPos;
         return peg$FAILED;
     }
  }) dummyText:('#'+ / '_'+) {
      var dp = inclTag.dataAttribs;
      if (dummyText.length !== dp.skipLen || dummyText[0] !== dp.skipChar) {
          peg$currPos = peg$reportedPos;
          return peg$FAILED;
      }

      // Tokenize include content in a new tokenizer
      var inclContent = dp.src.substring(dp.tagWidths[0], dp.src.length - dp.tagWidths[1]),
          inclContentToks = (new PegTokenizer(options.env)).tokenize(inclContent);

      if (dp.tagWidths[1] > 0) {
          inclContentToks = Util.stripEOFTkfromTokens(inclContentToks);
      }

      // shift tsr
      Util.shiftTokenTSR(inclContentToks, dp.tsr[0] + dp.tagWidths[0]);

      // Reset input
      input = dp.origInput;

      // Clear temporary state
      dp.skipChar = undefined;
      dp.skipLen = undefined;
      dp.origInput = undefined;

      return [inclTag].concat(inclContentToks);
  }

// Start of file
sof = & { return peg$currPos === 0; }

// End of file
eof = & { return peg$currPos === input.length; }

newline = '\n' / '\r\n'

newlineToken = newline { return [new NlTk([peg$reportedPos, peg$currPos])]; }

eolf = newline / eof

comment_space_eolf = (space+ / comment)* (newline / eof)

// 'Preprocessor' directive- higher-level things that can occur in otherwise
// plain-text content.
directive
  = comment
  / nowiki
  / tplarg_or_template
  / & "&" e:htmlentity { return e; }
  / include_limits

// Plain text, but can contain templates, template arguments, comments etc-
// all stuff that is normally handled by the preprocessor
// Returns either a list of tokens, or a plain string (if nothing is to be
// processed).
preprocessor_text
  = r:( t:[^<~[{\n\r\t|!\]}{ &=]+ { return t.join(''); }
  / !inline_breaks dt:(
      directive
    / text_char ) { return dt; }
  )+ {
      // r will always be an array
      return tu.flattenIfArray( r );
  }

wikilink_preprocessor_text
  = r:( t:[^<[{\n\r\t|!\]}{ &]+ { return t.join(''); }
        // XXX gwicke: any more chars we need to allow here?
        / !inline_breaks wr:( directive / !"]]" c:( text_char / [!<] ) { return c; } )
        { return wr; }
    )+ {
      return tu.flatten_stringlist( r );
  }

extlink_preprocessor_text
  // added special separator character class inline: separates url from
  // description / text
  = r:( t:[^'<~[{\n\r|!\]}\t&="' \u00A0\u1680\u180E\u2000-\u200A\u202F\u205F\u3000]+ { return t.join(''); }
  / !inline_breaks r:( directive / no_punctuation_char ) { return r; }
  /// urlencoded_char
  // !inline_breaks no_punctuation_char
  / s:[.:,] !(space / eolf) { return s; }
  / q:['] !([']) { return q; } // single quotes are ok, double quotes are bad
  / [&%|{] )+ {
      return tu.flatten_string( r );
  }

// Attribute values with preprocessor support
attribute_preprocessor_text
  = r:( ts:(!inline_breaks t:[^=<>{}\n\r&'"\t/ ] {return t;})+ { return ts.join(''); }
  / !inline_breaks
    ! '/>'
    r:(
          directive
        / [&%/{}]
    ) { return r; }
  )+
  {
      //console.warn('prep');
      return tu.flatten_string( r );
  }

attribute_preprocessor_text_single
  = r:( t:[^{}&'<]+ { return t.join(''); }
  / !inline_breaks r:(
      directive
    / [{}&<] ) { return r; }
  )*
  {
      return tu.flatten_string( r );
  }
attribute_preprocessor_text_single_broken
  = r:( t:[^{}&'<>|]+ { return t.join(''); }
  / !inline_breaks r:(
      directive
    / [{}&<] ) { return r; }
  )*
  {
      return tu.flatten_string( r );
  }
attribute_preprocessor_text_double
  = r:( t:[^{}&"<]+ { return t.join(''); }
  / !inline_breaks r:(
      directive
    / [{}&<] ) { return r; }
  )*
  {
      //console.warn( 'double:' + pp(r) );
      return tu.flatten_string( r );
  }
attribute_preprocessor_text_double_broken
  = r:( t:[^{}&"<>|]+ { return t.join(''); }
  / !inline_breaks r:(
      directive
    / [{}&<] ) { return r; }
  )*
  {
      //console.warn( 'double:' + pp(r) );
      return tu.flatten_string( r );
  }

// Variants with the entire attribute on a single line
attribute_preprocessor_text_line
  = r:( ts:[^=<>{\n\r&'"\t \[\]|{}/!]+ { return ts.join(''); }
        /  !inline_breaks
            ! '/>'
            t:(
                directive
              // Eat insane tags-inside-attributes. Example:
              // <hiddentext>generated with.. </hiddentext>
              / &generic_tag nb:nested_block_line { return nb; }
              / !(space_or_newline / [\[>]) c:. {
                    //console.warn( 'aptl: ' + pp(c) );
                    return c;
                }
            ) { return t; }
      )+
  {
      //console.warn('prep');
      return tu.flatten_string( r );
  }

attribute_preprocessor_text_single_line
  = r:( t:[^{}&'<|!\n]+ { return t.join(''); }
  / !inline_breaks r:(
      directive
    / ![\r\n] q:[{}&<] { return q; } ) { return r; }
  )* {
      return tu.flatten_string( r );
  }
attribute_preprocessor_text_single_line_broken
  = r:( t:[^{}&'<>|!\n]+ { return t.join(''); }
  / !inline_breaks r:(
      directive
    / ![\r\n] q:[{}&<] { return q; } ) { return r; }
  )* {
      return tu.flatten_string( r );
  }
attribute_preprocessor_text_double_line
  = r:( t:[^{}&"<|!\n]+ { return t.join(''); }
  / !inline_breaks r:(
      directive
    / ![\r\n] q:[{}&<] { return q; } ) { return r; }
  )* {
      return tu.flatten_string( r );
  }
attribute_preprocessor_text_double_line_broken
  = r:( t:[^{}&"<>|!\n]+ { return t.join(''); }
  / !inline_breaks r:(
      directive
    / ![\r\n] q:[{}&<] { return q; } ) { return r; }
  )* {
      return tu.flatten_string( r );
  }

// Special-case support for those pipe templates
pipe = "|" / "{{!}}"

end_pipe = p:"|" ! "|" { return p; } / p:"{{!}}" ! "{{!}}" { return p; }

// SSS FIXME: what about |{{!}} and {{!}}|
pipe_pipe = "||" / "{{!}}{{!}}"

// Similar, for tables..
exclam = "!" / "{{;}}"

/* Tabs do not mix well with the hybrid production syntax */
/* vim: set filetype=javascript expandtab ts=4 sw=4 cindent : */
